---
layout: post
title:  "Image Quality Assessment Learning"
date:   2025-09-03 16:46:01 +0800
categories: CV IQA Learning
cover: "assets/images/default-cover.jpg"
comments: true
---


##  IQA Learning
#### 2025-09-03

## Introduction
这是笔者学习图像质量评价的指标（Image Quality Assessment，IQA）的笔记，这份笔记可能后续还会更新，期望的是汇总目前Computer Vision领域的IQA metrics，希望能够详细介绍它们的定义、算法、应用场景等等。

## Metrics
理论上，如果严格完整来说，应该首先分为主观评测指标和客观评测指标；主观评价指标大抵意思是找人来为图像质量打分，然后算均值之类；不适用于大规模快速的算法评判，在此先略过不表；

略举一例：
1. **招募观察者**：通常需10-20名无视觉障碍的观察者，避免专业背景偏差。
2. **制定评分标准**：采用国际通用的5分制（ITU-T P.910标准）：
   - 5分（Excellent）：无任何可察觉的失真，质量极佳；
   - 4分（Good）：有轻微可察觉的失真，但不影响整体质量；
   - 3分（Fair）：失真明显，但仍可接受；
   - 2分（Poor）：失真严重，影响使用；
   - 1分（Bad）：失真极严重，完全无法使用。
3. **统计MOS**：对所有观察者的打分取算术平均，公式为：  
   $$MOS = \frac{1}{N} \sum_{i=1}^N s_i$$  
   其中，$N$ 为观察者数量，$s_i$ 为第 $i$ 名观察者的打分。

主要下面讨论若干常用的客观评测指标。

（一） 全参考FR-IQA
### PSNR
峰值信噪比（Peak Signal-to-Noise Ratio, PSNR）

#### overview
概括来说：相当于就是像素级的


##### （1）核心用途
最经典、最常用的FR-IQA指标，广泛用于图像压缩（如JPEG）、视频编码（如H.264/H.265）的失真评估。

##### （2）核心思想
基于“信号与噪声的比值”：将失真视为“噪声”，参考图视为“信号”，PSNR越高，说明“信号占比越高，噪声（失真）越少”。

##### （3）计算方法
步骤1：计算**均方误差（MSE）**：衡量参考图与失真图的像素差异，公式为：  
$$MSE = \frac{1}{H \times W \times C} \sum_{x=1}^H \sum_{y=1}^W \sum_{c=1}^C (I(x,y,c) - J(x,y,c))^2$$  
其中，$H/W/C$ 分别为图像的高度、宽度、通道数（如RGB图像$C=3$），$I$ 为参考图，$J$ 为失真图，$(x,y,c)$ 为像素坐标。

步骤2：计算PSNR：基于MSE，引入“峰值像素值（MAX_I）”（如8位图像MAX_I=255），公式为：  
$$PSNR = 10 \times \log_{10}\left( \frac{MAX_I^2}{MSE} \right)$$  
单位：分贝（dB），值越大表示质量越好（通常合格范围：25-35dB，>35dB接近无失真）。

##### （4）优缺点
- **优点**：计算简单、速度快，可解释性强；
- **缺点**：仅关注像素级差异，与人类主观感知一致性差（例：PSNR高的图像可能因模糊/块效应让人生理不适，PSNR低的图像可能主观感受更清晰）。


### SSIM 
构相似性指数（Structural Similarity Index, SSIM）
##### （1）核心用途
解决PSNR“像素优先、结构忽略”的缺陷，更贴合人类视觉对“图像结构”的敏感度（如边缘、纹理），适用于图像去噪、超分辨率、风格迁移的质量评估。

##### （2）核心思想
人类视觉更关注“图像的结构信息”（而非单个像素），SSIM从**亮度（Luminance）**、**对比度（Contrast）**、**结构（Structure）** 三个维度对比参考图与失真图，三者乘积即为SSIM值。

##### （3）计算方法
步骤1：局部窗口处理：用高斯窗口（默认大小11×11）滑动遍历图像，避免单像素噪声影响。

步骤2：计算三个核心分量：
- **亮度分量（$l$）**：衡量两图的平均亮度差异，引入常数$C_1$避免分母为0：  
  $$l(I,J) = \frac{2\mu_I \mu_J + C_1}{\mu_I^2 + \mu_J^2 + C_1}$$  
  其中，$\mu_I/\mu_J$ 为参考图/失真图在窗口内的均值，$C_1=(K_1 \times MAX_I)^2$（$K_1=0.01$为经验值）。

- **对比度分量（$c$）**：衡量两图的对比度差异，引入常数$C_2$：  
  $$c(I,J) = \frac{2\sigma_I \sigma_J + C_2}{\sigma_I^2 + \sigma_J^2 + C_2}$$  
  其中，$\sigma_I/\sigma_J$ 为参考图/失真图在窗口内的标准差，$C_2=(K_2 \times MAX_I)^2$（$K_2=0.03$为经验值）。

- **结构分量（$s$）**：衡量两图的结构相关性，用协方差$\sigma_{IJ}$表示：  
  $$s(I,J) = \frac{\sigma_{IJ} + C_3}{\sigma_I \sigma_J + C_3}$$  
  其中，$\sigma_{IJ} = \frac{1}{N-1}\sum_{x,y}(I(x,y)-\mu_I)(J(x,y)-\mu_J)$，$C_3=C_2/2$。

步骤3：计算SSIM：三个分量的乘积，取值范围$[0,1]$，值越接近1表示质量越好：  
$$SSIM(I,J) = l(I,J) \times c(I,J) \times s(I,J)$$

##### （4）扩展：多尺度SSIM（MS-SSIM）
SSIM仅考虑单尺度结构，MS-SSIM通过**高斯下采样生成多尺度图像**（如5个尺度），在不同尺度下计算SSIM并加权（低频分量权重更高，符合人眼对全局结构的敏感度），进一步提升与主观感知的一致性。

##### （5）优缺点
- **优点**：关注结构信息，与主观感知一致性远优于PSNR；
- **缺点**：计算复杂度高于PSNR，对“非结构失真”（如色彩偏移）敏感度较低。


### 视觉信息保真度（Visual Information Fidelity, VIF）
##### （1）核心用途
基于“信息论”的FR-IQA指标，模拟人类视觉系统（HVS）的信息传递过程，对“模糊、压缩失真”的评价精度高于SSIM，适用于高精度图像质量评估（如医学图像、专业摄影）。

##### （2）核心思想
将参考图视为“信息源”，失真图视为“经过噪声干扰的信息接收端”，VIF通过计算“失真图传递给人眼的信息占参考图的比例”来衡量质量——比例越高，质量越好。

##### （3）计算方法
步骤1：模拟人类视觉系统：用多尺度小波分解（如3个尺度、4个方向）将图像分解为不同频率分量（HVS对不同频率的敏感度不同，高频对细节敏感，低频对全局敏感）。

步骤2：计算信息传递效率：对每个频率分量，假设参考图信号为$X$，失真图信号为$Y=X+N$（$N$为噪声），通过高斯模型估计信号与噪声的功率比（SNR），再计算信息保真度：  
$$VIF = \sum_{k} w_k \times \frac{I(X;Y_k)}{I(X;X_k)}$$  
其中，$w_k$ 为第$k$个频率分量的权重（贴合HVS敏感度），$I(X;Y_k)$ 为$X$与$Y_k$的互信息（传递的信息），$I(X;X_k)$ 为$X$与自身的互信息（原始信息）。

步骤3：VIF取值范围$[0,1]$，值越接近1表示信息损失越少，质量越好。

##### （4）优缺点
- **优点**：与主观感知一致性最优（优于SSIM），能捕捉HVS对不同频率的敏感度；
- **缺点**：计算复杂度极高，速度慢，不适用于实时场景。


### 特征相似性指数（Feature Similarity Index, FSIM）
##### （1）核心用途
结合“结构特征”和“相位信息”，对“模糊、旋转、缩放失真”的鲁棒性优于SSIM，适用于图像配准、目标检测中的质量评估。

##### （2）核心思想
人类视觉对“图像相位”（反映边缘、纹理的位置和结构）的敏感度远高于“幅度”，FSIM通过提取**相位一致性（PC）** 和**梯度幅度（GM）** 两个核心特征，对比参考图与失真图的特征相似性。

##### （3）计算方法
步骤1：提取相位一致性（PC）：用Log-Gabor滤波器计算图像的相位信息（PC值越高，边缘越清晰）。

步骤2：提取梯度幅度（GM）：用Sobel算子计算图像的梯度（反映像素灰度变化率，GM值越高，纹理越丰富）。

步骤3：计算特征相似性：对PC和GM分别计算相似性（采用与SSIM类似的局部窗口方法），再加权融合：  
$$FSIM = \frac{\sum_{x,y} [PC_I(x,y) + PC_J(x,y)] \times S_{GM}(x,y)}{\sum_{x,y} [PC_I(x,y) + PC_J(x,y)]}$$  
其中，$S_{GM}$ 为GM的相似性，取值范围$[0,1]$，值越接近1表示质量越好。

##### （4）优缺点
- **优点**：对几何失真（旋转、缩放）和模糊失真鲁棒性强；
- **缺点**：对噪声敏感，计算复杂度高于SSIM。



### WADIQAM-FR（全参考）
**核心用途**：针对视频编码、图像压缩等场景的高精度失真评估，尤其适用于对抗性攻击鲁棒性测试。  
**核心思想**：  
- 基于孪生CNN网络（权值共享的VGG-like结构），提取参考图与失真图的特征向量。  
- 引入**加权平均池化**（Weighted Average Patch Aggregation），通过学习每个图像块的权重，动态调整局部失真对全局质量的贡献。  
- 采用L1损失函数优化，减少对异常值的敏感度，提升低失真区域的评估精度。  

**计算步骤**：  
1. **特征提取**：输入图像对经孪生网络提取多尺度特征（如5层卷积输出）。  
2. **特征融合**：将参考图与失真图的特征向量逐元素相减，拼接形成差异特征。  
3. **权重回归**：通过全连接层预测每个图像块的权重（ReLU激活确保非负性）。  
4. **质量聚合**：加权平均各块质量得分，公式为：  
   $$Q = \frac{\sum_{i=1}^N w_i \cdot q_i}{\sum_{i=1}^N w_i}$$  
   其中$w_i$为第$i$块的权重，$q_i$为块质量预测值。  

**优缺点**：  
- 优点：在TID2013数据集上PLCC达0.971，显著优于传统FR-IQA（如SSIM的0.959）。  
- 缺点：计算复杂度较高，需GPU加速。




### DISTS：基于CNN
（深度图像结构与纹理相似性）
#### 1. 核心用途
DISTS（Deep Image Structure and Texture Similarity）是**基于深度学习的全参考图像质量指标**，专为解决传统FR-IQA对复杂失真（如GAN生成伪影、轻微几何变形）评估失效的问题设计。其核心优势在于**同时捕捉图像的结构信息（如边缘、轮廓）和纹理细节（如材质、粗糙度）**，与人类主观感知的一致性显著优于SSIM、VIF等传统指标，尤其适用于AI生成图像（如GAN）、超分辨率、图像修复等场景。

#### 2. 核心思想
DISTS通过**孪生CNN网络**（权值共享的VGG-16变体）提取参考图与失真图的多尺度特征，结合**结构相似性改进模块**和**纹理感知模块**，动态融合局部与全局信息：
- **结构相似性**：基于改进的SSIM算法，引入**跨通道注意力机制**，增强对边缘和轮廓的敏感度。
- **纹理感知**：通过**局部二值模式（LBP）**和**高斯差分（DoG）**提取纹理特征，量化纹理复杂度和重复性。
- **动态加权融合**：通过可学习的权重参数，自动平衡结构与纹理信息对最终质量得分的贡献。

#### 3. 计算方法
**步骤1：特征提取**  
输入参考图$I_r$和失真图$I_d$，通过孪生CNN提取5层多尺度特征（如Conv1_1到Conv5_1），每层特征图维度为$C \times H \times W$。

**步骤2：结构相似性计算**  
对每层特征图计算结构相似度$S_l$，公式为：  
$$S_l = \frac{2\mu_{r,l}\mu_{d,l} + C_1}{(\mu_{r,l}^2 + \mu_{d,l}^2) + C_1} \cdot \frac{2\sigma_{r,l}\sigma_{d,l} + C_2}{(\sigma_{r,l}^2 + \sigma_{d,l}^2) + C_2}$$  
其中$\mu_{r,l}/\mu_{d,l}$为参考图/失真图在第$l$层的均值，$\sigma_{r,l}/\sigma_{d,l}$为标准差，$C_1/C_2$为防止分母为0的常数。

**步骤3：纹理相似性计算**  
对每层特征图应用LBP和DoG滤波器，生成纹理响应图$T_l$，计算纹理相似度$T_l$：  
$$T_l = \frac{1}{N} \sum_{i=1}^N \left(1 - \frac{|T_{r,l}(i) - T_{d,l}(i)|}{\max(T_{r,l}) - \min(T_{r,l})}\right)$$  
其中$N$为像素总数，$T_{r,l}/T_{d,l}$为参考图/失真图的纹理响应值。

**步骤4：多尺度融合与加权**  
将各层结构相似度$S_l$和纹理相似度$T_l$进行加权求和，高层特征（如Conv5_1）权重更高：  
$$DISTS = \sum_{l=1}^5 w_l \cdot (S_l + T_l)$$  
其中$w_l$通过主观评分数据训练确定，取值范围$[0,1]$，且$\sum w_l = 1$。

#### 4. 性能表现
- **主观一致性**：在TID2013数据集上PLCC（皮尔逊相关系数）达0.971，显著优于SSIM（0.959）和VIF（0.963）。
- **抗失真鲁棒性**：对JPEG压缩（质量因子10-90）、高斯模糊（σ=0.5-3.0）、椒盐噪声（密度0.01-0.05）等失真类型的区分度提升20%-30%。
- **计算效率**：单张256×256图像评估耗时约120ms（RTX 3090），支持实时视频流质量监控。

#### 5. 应用场景
- **AI生成图像评估**：如GAN生成图的伪影检测、风格迁移的细节保留度分析。
- **医疗影像处理**：MRI/CT图像的去噪效果评估，对微小病灶的结构完整性敏感度高。
- **工业检测**：机械零件表面缺陷识别，结合纹理特征区分划痕与正常纹理。

#### 6. 优缺点对比

| 优势 | 局限性 |
|------------------------------|-----------------------------|
| 同时捕捉结构与纹理信息，贴合人类感知 | 依赖预训练CNN模型，需GPU加速 |
| 对几何变形（如旋转、缩放）鲁棒性强 | 对色彩偏移、光照变化敏感度较低 |
| 可作为优化目标函数，直接嵌入生成模型 | 模型参数规模较大（约50MB） |


| 指标       | 核心差异点 | 典型应用场景 |
|------------|------------|--------------|
| **DISTS**  | 结构+纹理双模态特征，动态加权 | GAN生成图、医学影像 |




### 总结
DISTS通过**深度学习+多模态特征融合**，在图像质量评估领域实现了从“像素差异”到“感知理解”的跨越。其结构-纹理双模态设计不仅提升了对复杂失真的检测精度，还为生成模型优化提供了可微分的目标函数。随着生成式AI的普及，DISTS这类贴合人类视觉本质的指标将成为图像质量评估的核心工具，推动计算机视觉从“看得清”向“看得懂”演进。



（二） 半参考图像质量指标（RR-IQA）
仅需**参考图的部分特征（如边缘、纹理统计量）**，无需完整参考图，平衡了FR-IQA的精度和NR-IQA的灵活性，适用于“参考图无法完整获取”的场景（如网络传输中参考图丢包、实时监控视频）。

#### 核心指标：基于小波特征的半参考指标（以IRNI为例）
##### 1. 核心用途
用于图像传输中的失真评估（如卫星图像、监控视频传输），仅需参考图的小波系数统计量，无需传输完整参考图。

##### 2. 核心思想
参考图的“小波系数统计特征”（如均值、方差、熵）能反映其核心结构，失真会改变这些统计特征，通过对比失真图与参考图的特征差异评估质量。

##### 3. 计算方法
步骤1：参考端预处理：对参考图进行小波分解（如2级Daubechies小波），提取各频率子带的统计特征（如均值$\mu_r$、方差$\sigma_r$、熵$H_r$），并将这些特征传输到失真端。

步骤2：失真端特征提取：对失真图进行相同的小波分解，提取对应子带的统计特征（$\mu_d$、$\sigma_d$、$H_d$）。

步骤3：计算特征差异：用欧氏距离或余弦相似度衡量两者的特征差异，再映射为质量分数：  
$$RR-IQA\ Score = 1 - \frac{\sqrt{(\mu_r-\mu_d)^2 + (\sigma_r-\sigma_d)^2 + (H_r-H_d)^2}}{\sqrt{\mu_r^2 + \sigma_r^2 + H_r^2}}$$  
取值范围$[0,1]$，值越接近1表示质量越好。

##### 4. 优缺点
- **优点**：无需完整参考图，减少数据传输量；精度优于NR-IQA；
- **缺点**：依赖参考图的特征设计（特征选择不当会导致精度下降），适用场景较窄。


（三） 无参考图像质量指标（NR-IQA）
**无需任何参考图**，仅通过分析失真图自身的特征（如自然场景统计、语义结构）评估质量，是最具实用性的指标之一，适用于“无法获取参考图”的场景（如网络图片、监控视频、用户上传内容）。

### 盲图像质量指数（Blind Image Quality Index, BRISQUE）
##### （1）核心用途
最经典的NR-IQA指标，用于自然图像（如风景、人像）的质量评估，广泛集成于图像编辑软件（如Photoshop）、社交平台（如微信图片压缩评估）。

##### （2）核心思想
“自然图像具有固定的统计规律”（如局部对比度服从高斯分布），失真会破坏这种规律——BRISQUE通过提取失真图的“自然场景统计（NSS）特征”，用机器学习模型预测质量分数。

（这也是为什么brisque在自然图像上更权威一些，但医学等等专业图就不太好用）

##### （3）计算方法
步骤1：预处理：对失真图进行**均值减法对比度归一化（MSCN）**，消除光照和全局对比度的影响，提取局部纹理特征：  
$$MSCN(x,y) = \frac{I(x,y) - \mu(x,y)}{\sigma(x,y) + C}$$  
其中，$\mu(x,y)$ 为局部窗口均值，$\sigma(x,y)$ 为局部窗口标准差，$C$为常数（避免分母为0）。

步骤2：提取NSS特征：计算MSCN系数的统计特征（如均值、方差、偏度、峰度），以及MSCN系数的邻域相关性特征（共36维特征）。

步骤3：质量预测：用训练好的**支持向量回归（SVR）模型**将特征映射为质量分数，取值范围$[0,100]$，分数越高表示质量越好。

##### （4）优缺点
- **优点**：适用于多种失真类型（压缩、噪声、模糊），精度较高；
- **缺点**：依赖自然图像训练集，对非自然图像（如医学图像、卡通）评估偏差大。


### 自然图像质量评估器（Natural Image Quality Evaluator, NIQE）
##### （1）核心用途
无需训练数据的NR-IQA指标，适用于“缺乏标注训练集”的场景（如特殊领域图像）。

##### （2）核心思想
自然图像的“局部统计特征”（如亮度、对比度）服从特定的多元高斯分布，失真会导致特征分布偏离自然分布——NIQE通过计算“失真图特征分布与自然图像特征分布的距离”评估质量。

##### （3）计算方法
步骤1：预定义自然图像特征分布：基于大量无失真自然图像，提取“亮度归一化后的局部标准差”和“局部梯度幅度”特征，拟合多元高斯分布模型（均值$\mu_n$、协方差$\Sigma_n$）。

步骤2：提取失真图特征：对失真图提取相同的局部特征，拟合其多元高斯分布模型（均值$\mu_d$、协方差$\Sigma_d$）。

步骤3：计算分布距离：用**马氏距离（Mahalanobis Distance）** 衡量两个分布的差异，距离越小表示质量越好：  
$$NIQE\ Score = \sqrt{(\mu_d - \mu_n)^T \Sigma_n^{-1} (\mu_d - \mu_n) + \text{tr}(\Sigma_n^{-1} \Sigma_d) - \ln(\det(\Sigma_n^{-1} \Sigma_d)) - K}$$  
其中，$\text{tr}$为矩阵迹，$\det$为矩阵行列式，$K$为特征维度。

##### （4）优缺点
- **优点**：无需训练，鲁棒性强，对多种失真类型适用；
- **缺点**：精度略低于BRISQUE，对“失真程度低”的图像区分度差。


### LPIPS:经典的基于深度学习的NR-IQA
##### （1）核心用途
近年来主流的高精度NR-IQA指标，适用于图像生成（如GAN生成图）、超分辨率、风格迁移的质量评估，贴合人类高层语义感知。

##### （2）核心思想
传统NR-IQA依赖低层特征（像素、梯度），深度学习模型（如CNN）可提取“高层语义特征”（如物体形状、纹理结构），更接近人类视觉的认知过程——LPIPS（Learned Perceptual Image Patch Similarity）通过预训练CNN提取特征，计算失真图与“理想自然图像”的特征距离（注：LPIPS本质是FR-IQA，但可通过“生成理想自然图像”扩展为NR-IQA）。

##### （3）计算方法
步骤1：预训练CNN模型：使用在ImageNet上预训练的CNN（如VGG-16、AlexNet），去除最后全连接层，保留卷积层（用于提取特征）。

步骤2：特征提取与归一化：对失真图和理想自然图像（如通过超分模型生成的参考图）输入CNN，提取各层特征，并进行L2归一化。

步骤3：计算感知距离：对各层特征计算L2距离，加权求和（高层特征权重更高），距离越小表示质量越好：  
$$LPIPS = \sum_{l=1}^L w_l \times \frac{1}{H_l W_l C_l} \sum_{x,y,c} (F_l(I_d, x,y,c) - F_l(I_r, x,y,c))^2$$  
其中，$L$为CNN层数，$w_l$为第$l$层权重，$F_l$为第$l$层特征，$I_d$为失真图，$I_r$为理想参考图。

##### 特点
- **优点**：基于高层语义特征，与主观感知一致性最优；
- 依赖预训练CNN和理想参考图（扩展为NR-IQA时需额外模型）。



### WADIQAM-NR同样基于深度神经网络（无参考）
**核心用途**：适用于社交媒体图像、监控视频等无参考场景，对JPEG压缩、噪声、模糊等失真类型鲁棒。  
**核心思想**：  
- 继承WADIQAM-FR的多尺度特征提取框架，但去除参考图输入。  
- 引入**跨通道注意力机制**（Cross-Channel Attention），增强对局部纹理和边缘的敏感度。  
- 采用**空间金字塔池化**（Spatial Pyramid Pooling）融合不同区域的特征统计量（如均值、方差）。  

**计算步骤**：  
1. **多尺度特征提取**：通过3个并行分支处理不同分辨率的输入（原图、1/2缩放、1/4缩放）。  
2. **注意力增强**：对每个分支的特征图计算通道间相关性，生成注意力权重。  
3. **全局聚合**：将多尺度特征拼接后输入全连接层，回归质量分数。  

**性能表现**：在CLIVE数据集上SROCC达0.601，优于BRISQUE（0.557）和NIQE（0.477）。



### CLIPIQA：基于CLIP
**核心用途**：基于CLIP模型的无参考指标，适用于AI生成图像（如GAN）、艺术创作等抽象感知评估。  
**核心思想**：  
- 利用CLIP的跨模态对齐能力，将图像质量映射到文本语义空间。  
- **反义词提示配对策略**：例如同时使用“高质量照片”和“低质量照片”作为提示，通过余弦相似度差消除语义歧义。  
- 移除位置嵌入（Position Embedding），支持任意尺寸输入，减少缩放引入的伪失真。  

**计算步骤**：  
1. **特征提取**：CLIP的图像编码器输出图像特征$F_I$，文本编码器输出提示特征$F_T^+$和$F_T^-$。  
2. **相似度计算**：  
   $$S^+ = \text{cosine}(F_I, F_T^+), \quad S^- = \text{cosine}(F_I, F_T^-)$$  
3. **质量得分**：通过Softmax归一化后取差值：  
   $$Q = \frac{e^{S^+}}{e^{S^+} + e^{S^-}} - \frac{e^{S^-}}{e^{S^+} + e^{S^-}}$$  
   取值范围$[-1, 1]$，正值表示质量更高。  

**技术突破**：  
- 在AVA美学数据集上PLCC达0.8978，超越传统方法（如NIMA的0.823）。  
- 支持细粒度评估（如亮度、噪声）和抽象属性（如“快乐”“悲伤”），通过提示词扩展可适应多种场景。  

**局限性**：  
- 对专业术语（如医学图像中的伪影）的敏感度不足；  


### PI（Perceptual Index）：基于CNN
**核心用途**：基于预训练CNN的无参考指标，适用于自然图像的美学评分和质量筛选。  
**核心思想**：  
- 模拟人类视觉系统的多通道响应，提取图像的**空域感知信息（SI）**和**时域感知信息（TI）**。  
- SI通过Sobel滤波计算边缘密度，TI通过相邻帧差异计算运动强度，最终得分由两者加权融合。  

**计算步骤**：  
1. **空域分析**：  
   $$SI = \max\left(\sigma\left(Sobel(I)\right)\right)$$  
   其中$\sigma$为标准差，反映边缘细节丰富度。  
2. **时域分析**：  
   $$TI = \max\left(\sigma\left(I_t - I_{t-1}\right)\right)$$  
   反映连续帧间的运动剧烈程度。  
3. **质量评分**：  
   $$Q = w_S \cdot SI + w_T \cdot TI$$  
   权重$w_S$和$w_T$通过主观评分数据训练确定。  

**应用场景**：  
- 摄影作品筛选、社交媒体内容推荐；  
- 与NIMA相比，对低对比度、模糊等失真更敏感。  

**局限性**：  
- 对非自然图像（如卡通、抽象艺术）效果较差；  
- 需依赖标注数据训练权重。

### MANIQA
**核心用途**：针对GAN生成图像的无参考指标，解决传统方法对生成失真（如伪影、纹理不连贯）评估失效的问题。  
**核心思想**：  
- 结合ViT和多维度注意力机制，捕捉全局结构与局部细节的交互。  
- **转置注意力块（TAB）**：在通道维度计算全局均值和最大值，生成通道注意力权重。  
- **尺度Swin Transformer块（SSTB）**：在空间维度应用窗口划分，增强局部纹理感知。  

**计算步骤**：  
1. **图像分块**：将输入图像划分为8×8像素块，线性投影为768维特征向量。  
2. **多尺度特征提取**：通过ViT编码器提取3个尺度的特征（原图、1/2缩放、1/4缩放）。  
3. **注意力增强**：  
   - TAB计算通道权重，SSTB计算空间权重。  
   - 融合后的特征通过全连接层回归每个块的质量得分。  
4. **全局聚合**：  
   $$Q = \sum_{i=1}^N \alpha_i \cdot q_i$$  
   其中 $\alpha_i$ 为块的空间注意力权重，$q_i$ 为块质量预测值。  

**性能表现**：  
- 在NTIRE 2022无参考赛道排名第一，在LIVE数据集上PLCC达0.972，显著优于BRISQUE（0.822）。  
- 对生成图像的伪影、纹理断裂等缺陷的检测准确率超过90%。







## 指标对比与选择指南

| 指标       | 类型   | 核心优势                                | 适用场景                          | 计算复杂度参考 |
|------------|--------|-----------------------------------------|-----------------------------------|---------------|
| WADIQAM-FR | FR     | 高精度，对抗性攻击鲁棒性强              | 视频编码、专业图像处理            | 4         |
| CLIPIQA    | NR     | 支持抽象感知评估，适配AI生成图像        | GAN质量控制、艺术创作            | 4        |
| MANIQA     | NR     | 针对生成失真优化，检测准确率高          | GAN生成图像、超分辨率            | 5     |
| PI         | NR     | 结合空域/时域特征，贴近美学感知        | 自然图像筛选、社交媒体内容审核    | 3         |




| 场景需求                | 推荐指标                | 原因分析                                  |
|-------------------------|-------------------------|-------------------------------------------|
| 有参考图、实时计算      | PSNR、SSIM              | 计算快，适用于视频编码、实时去噪          |
| 有参考图、高精度评估    | MS-SSIM、VIF、FSIM      | 贴合主观感知，适用于医学图像、专业摄影    |
| 无参考图、自然图像      | BRISQUE、NIQE           | 鲁棒性强，适用于网络图片、监控视频        |
| 无参考图、生成式图像    | LPIPS（深度学习）       | 捕捉高层语义，适用于GAN生成图、风格迁移  |
| 参考图不完整、低带宽    | 小波基RR-IQA            | 仅需特征传输，适用于卫星图像、远程监控    |


